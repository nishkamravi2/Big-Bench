#!/usr/bin/env bash

helpModule () {
  echo "This module runs a single query on a single stream"
  echo
  echo "Options:"
  echo -e "-q\tquery number to run (required)"
  echo -e "-d\tdatabase to use"
  echo -e "-D\tquery part to debug"
  echo -e "-h\tshow this help"
  echo -e "-p\tbenchmark phase to use"
  echo -e "-t\tstream number for query run"
  echo -e "-y\tfile with user defined query parameters"
  echo -e "-z\tfile with user defined engine settings"
}

runModule () {
  if ! runCmdWithErrorCheck initQueryEnv
  then
    return 1
  fi

  echo "==============================================="
  echo "Running query : $QUERY_NAME"
  echo "-----------------------------------------------"
  echo "benchmark phase: $BIG_BENCH_BENCHMARK_PHASE"
  echo "stream number  : $BIG_BENCH_STREAM_NUMBER"
  echo "user parameter file: $USER_QUERY_PARAMS_FILE"
  echo "user settings file : $USER_ENGINE_SETTINGS_FILE"
  if [ -n "$DEBUG_QUERY_PART" ]
  then
    echo "query part to debug: $DEBUG_QUERY_PART"
  fi
  echo "log: $LOG_FILE_NAME"
  echo "==============================================="

  ### Checking required folder: logs/; tmp/; result/ if they exist, create them and set permissions

  echo "checking existence of local: $BIG_BENCH_LOGS_DIR"
  if [ ! -d "$BIG_BENCH_LOGS_DIR" ]; then
    mkdir -p "$BIG_BENCH_LOGS_DIR"
  fi

  if [ ! -e "$LOG_FILE_NAME" ] ; then
      touch "$LOG_FILE_NAME"
  fi

  if [ ! -w "$LOG_FILE_NAME" ] ; then
      echo "ERROR: cannot write to: $LOG_FILE_NAME, no permission"
      return 1
  fi

  echo "creating folders and setting permissions"
  runCmdWithErrorCheck hadoop fs -rm -r -f -skipTrash "${RESULT_DIR}"
  runCmdWithErrorCheck hadoop fs -rm -r -f -skipTrash "${TEMP_DIR}"
  runCmdWithErrorCheck hadoop fs -mkdir -p "${RESULT_DIR}"
  runCmdWithErrorCheck hadoop fs -mkdir -p "${TEMP_DIR}"
  runCmdWithErrorCheck hadoop fs -chmod ugo+rw "${BIG_BENCH_HDFS_ABSOLUTE_TEMP_DIR}"
  runCmdWithErrorCheck hadoop fs -chmod ugo+rw "${BIG_BENCH_HDFS_ABSOLUTE_QUERY_RESULT_DIR}"
  runCmdWithErrorCheck hadoop fs -chmod ugo+rw "${RESULT_DIR}"
  runCmdWithErrorCheck hadoop fs -chmod ugo+rw "${TEMP_DIR}"

  # start timed execution of query. Stderr is appended to stdout and both are written into logs/q??.log and to console

  # Run the main method implemented in the query's run.sh
  TIME_MEASUREMENT_FILE="`mktemp`"
  echo "======= $TABLE_PREFIX time =========" > "$TIME_MEASUREMENT_FILE"
  { time "$QUERY_MAIN_METHOD" > >(tee -a "$LOG_FILE_NAME") 2>&1 ; } 2>> "$TIME_MEASUREMENT_FILE"
  cat "$TIME_MEASUREMENT_FILE" >> "$LOG_FILE_NAME"
  rm -rf "$TIME_MEASUREMENT_FILE"
  echo "==========================="

  echo "======= $TABLE_PREFIX result =======" | tee -a "$LOG_FILE_NAME" 2>&1
  echo "results in: $RESULT_DIR" | tee -a "$LOG_FILE_NAME" 2>&1
  echo "to display: hadoop fs -cat $RESULT_DIR/*" | tee -a "$LOG_FILE_NAME" 2>&1
  echo "=========================" | tee -a "$LOG_FILE_NAME" 2>&1
}
