#!/usr/bin/env bash

helpModule () {
  echo "This module cleans all query results from HDFS as well as from the metastore for one query"
  echo
  echo "Options:"
  echo -e "-q\tquery number to run (required)"
  echo -e "-d\tdatabase to use"
  echo -e "-h\tshow this help"
  echo -e "-p\tbenchmark phase to use"
  echo -e "-t\tstream number for query run"
  echo -e "-z\tfile with user defined engine settings"
}

runModule () {
  if ! initQueryEnv
  then
    return 1
  fi

  echo "==============================================="
  echo "Cleaning query : $QUERY_NAME"
  echo "-----------------------------------------------"
  echo "benchmark phase: $BIG_BENCH_BENCHMARK_PHASE"
  echo "stream number  : $BIG_BENCH_STREAM_NUMBER"
  echo "user parameter file: $USER_QUERY_PARAMS_FILE"
  echo "user settings file : $USER_ENGINE_SETTINGS_FILE"
  if [ -n "$DEBUG_QUERY_PART" ]; then
    echo "query part to debug: $DEBUG_QUERY_PART"
  fi
  echo "log: $LOG_FILE_NAME"
  echo "==============================================="

  ### Checking required folder: logs/; tmp/; result/ if they exist, create them and set permissions

  # Run the clean method implemented in the query's run.sh
  runCmdWithErrorCheck "$QUERY_CLEAN_METHOD"

  echo "cleaning dir $RESULT_DIR"
  runCmdWithErrorCheck hadoop fs -rm -r -f -skipTrash "$RESULT_DIR"

  echo "cleaning dir $TEMP_DIR"
  runCmdWithErrorCheck hadoop fs -rm -r -f -skipTrash "$TEMP_DIR"

  wait

  echo "cleaning log $LOG_FILE_NAME"
  rm -rf "$LOG_FILE_NAME"
}
